{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A3_Create_and_Test_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workbook **creates** and **test** the model. \n",
    "\n",
    "This entails the following steps:\n",
    "\n",
    "| No.     | Step                                          |\n",
    "| :-------| :---------------------------------------------|\n",
    "| A3.1    | Import Libraries                              |\n",
    "| A3.2    | Load Images                                   |\n",
    "| A3.3    | Split Into Train and Test                     |\n",
    "| A3.4    | Create Model                                  |\n",
    "| A3.5    | Test Model                                    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A3.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from skimage.color import rgb2lab, deltaE_cie76\n",
    "import cv2\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.python.keras import layers, models, Model, optimizers\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A3.2 Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load images\n",
    "data_dir = '../deepfashionextract3/img/'\n",
    "categories = ['top', 'skirt', 'dress']\n",
    "\n",
    "data = []\n",
    "\n",
    "def create_data():\n",
    "    \n",
    "    for category in categories:\n",
    "        path = os.path.join(data_dir, category)\n",
    "        label = categories.index(category)\n",
    "\n",
    "        for filename in os.listdir(path):\n",
    "            #Load image\n",
    "            img_data = os.path.join(path, filename)\n",
    "            image = cv2.imread(img_data)\n",
    "            \n",
    "            try:\n",
    "                image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "                #Minimize to approx. one third\n",
    "                image = cv2.resize(image, (96,96))\n",
    "                image = np.array(image, dtype=np.float32)\n",
    "                \n",
    "                data.append([image, label])\n",
    "            \n",
    "            except Exception as e:\n",
    "                pass\n",
    "            \n",
    "    print(len(data))\n",
    "    \n",
    "    #wb for write and binary\n",
    "    pick = open('a_data.pickle', 'wb')\n",
    "    pickle.dump(data, pick)\n",
    "    pick.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    #rb for read and binary\n",
    "    pick = open('a_data.pickle', 'rb')\n",
    "    data = pickle.load(pick)\n",
    "    pick.close()\n",
    "    \n",
    "    #Shuffle the data\n",
    "    np.random.shuffle(data)\n",
    "    \n",
    "    feature = []\n",
    "    labels = []\n",
    "    \n",
    "    for img, label in data:\n",
    "        feature.append(img)\n",
    "        labels.append(label)\n",
    "        \n",
    "    feature = np.array(feature, dtype=np.float32 )\n",
    "    labels = np.array(labels)\n",
    "        \n",
    "    ##Normalize the pixels between 0 and 1\n",
    "    feature = feature/255.0\n",
    "    \n",
    "    return [feature, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A3.3 Split Into Train and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we do not have a large dataset only **10%** is saved for **test** so that more data can be used for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unpack feature and labels\n",
    "(feature, labels) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature, labels, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar(y, loc='left', relative=True):\n",
    "    width = 0.35\n",
    "    if loc == 'left':\n",
    "        n = -0.5\n",
    "    elif loc == 'right':\n",
    "        n = 0.5\n",
    " \n",
    "    # calculate counts per type and sort, to ensure their order\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    sorted_index = np.argsort(unique)\n",
    "    unique = unique[sorted_index]\n",
    " \n",
    "    if relative:\n",
    "        # plot as a percentage\n",
    "        counts = 100*counts[sorted_index]/len(y)\n",
    "        ylabel_text = '% Count'\n",
    "    else:\n",
    "        # plot counts\n",
    "        counts = counts[sorted_index]\n",
    "        ylabel_text = 'count'\n",
    " \n",
    "    xtemp = np.arange(len(unique))\n",
    " \n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.bar(xtemp + n*width, counts, align='center', alpha=.7, width=width)\n",
    "    labels = ['Top', 'Skirt', 'Dress']\n",
    "    plt.xticks(xtemp, labels)\n",
    "    plt.ylabel(ylabel_text)\n",
    "    plt.suptitle('Images per Category')\n",
    "    \n",
    "plot_bar(y_train, loc='left')\n",
    "plot_bar(y_test, loc='right')\n",
    "plt.legend([\n",
    "    'Train: ({0} images)'.format(len(y_train)),\n",
    "    'Test: ({0} images)'.format(len(y_test)), \n",
    "], loc=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A3.4 Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is created with **6 convolutional and pool layers and pools** to which the input sequentially passes.\n",
    "\n",
    "Adjusting the hyperparameters, the following has proven to achieve an optimal result with the data at hand:\n",
    "\n",
    "| No. | Findings                                                                         |\n",
    "|:----|:---------------------------------------------------------------------------------|\n",
    "| 1.  | 6 convolutional and pool layers rather than smaller and higher numbers of layers |\n",
    "| 2.  | 96 filters rather than a mix of 32, 64 and 96 filters                            |\n",
    "| 3.  | 512 neurons rather than 128 neurons                                              |\n",
    "| 4.  | Adding a dropout layer                                                           |\n",
    "| 5.  | A dropout layer of 70% rather than 50% or 90%                                    |\n",
    "| 6.  | 15 epochs rather than 10, 12 or 20                                               |\n",
    "\n",
    "At **12 epochs** an approx. **90% training accuracy** is already achieved. 15 epochs may only lead to an approx. **2%.** increase of test accuracy. At 20 epochs the accuracy decreases again which may be due to **overfitting**.\n",
    "It is also important to note that running the same model under same conditions may also lead to a  result with an approx. **2%** variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display categories for labels\n",
    "categories = ['top', 'skirt', 'dress']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input is pixel and 3 indicating RGB\n",
    "input_layer = tf.keras.layers.Input([96, 96, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From input_layer to conv_1\n",
    "#Same padding means the size of the output feature maps are the same as the input feature maps.\n",
    "conv_1 = tf.keras.layers.Conv2D(filters=96, kernel_size=(5,5), padding='same', activation='relu') (input_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From convolutional layer 1 to pool layer 1\n",
    "pool_1 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(conv_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From pool layer 1 to convolutional layer 2\n",
    "conv_2 = tf.keras.layers.Conv2D(filters=96, kernel_size=(3,3), padding='same', activation='relu') (pool_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pool with strides\n",
    "pool_2 = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(conv_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Increase of filters\n",
    "conv_3 = tf.keras.layers.Conv2D(filters=96, kernel_size=(3,3), padding='same', activation='relu') (pool_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same like pool layer 2\n",
    "pool_3 = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(conv_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten\n",
    "flt_1 = tf.keras.layers.Flatten()(pool_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dense layer with 512 neurons\n",
    "dn_1 = tf.keras.layers.Dense(512, activation='relu')(flt_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = tf.keras.layers.Dropout(0.7)(dn_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since 6 layers have been created, argument takes 6\n",
    "out = tf.keras.layers.Dense(6, activation='softmax')(dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create model - 1 \n",
    "model = tf.keras.Model(input_layer, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create model - 2\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit model \n",
    "history = model.fit(X_train, y_train, batch_size=20, epochs=15)\n",
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following shows a summary of the **hyperparameters**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "from keras.models import load_model\n",
    "model.save('A_recognition.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A3.5 Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test accuracy is approx. **72%**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model.evaluate(X_test, y_test, verbose=1)\n",
    "history2[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the sample below, the predictions of **seven of nine** images are correct. As a side note, the images have a low resolution because after drastically resizing them, they cannot be restored to their original. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot predictions\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.style.use('fivethirtyeight')\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    image = cv2.resize(X_test[i], (224, 224))\n",
    "    plt.imshow(image)\n",
    "    #np.argmax returns the position of the largest value\n",
    "    plt.xlabel('Actual:'+categories[y_test[i]]+'\\n'+'Predicted:'+categories[np.argmax(y_pred[i])])\n",
    "    plt.xticks([])\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=1.2, top=1.4, wspace=None, hspace=None)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than the sample above might suggest, the **confusion matrix** shows that the model does not favor tops. Moreover, the majority of predictions is correct (see lighter blue diagonal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_pred\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot confusion matrix\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(cm, annot = True, linewidths=0.5, square=True, cmap='Blues_r')\n",
    "plt.ylabel('Actual')\n",
    "plt.xticks([0, 1, 2], ['Top', 'Skirt', 'Dress'])\n",
    "plt.yticks([0, 1, 2], ['Top', 'Skirt', 'Dress'])\n",
    "plt.xlabel('Predicted')\n",
    "title='Accuracy: {0}'.format(history2[1])\n",
    "plt.title(title, size=15)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
