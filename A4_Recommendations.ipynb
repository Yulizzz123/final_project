{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A4_Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workbook **creates** and **test** the model. \n",
    "\n",
    "This entails the following steps:\n",
    "\n",
    "| No.     | Step                                          |\n",
    "| :-------| :---------------------------------------------|\n",
    "| A4.1    | Import Libraries                              |\n",
    "| A4.2    | Load Images                                   |\n",
    "| A4.3    | Load Model                                    |\n",
    "| A4.4    | Load Different Dataset                        |\n",
    "| A4.5    | Recommendations                               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A4.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from skimage.color import rgb2lab, deltaE_cie76\n",
    "import cv2\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.python.keras import layers, models, Model, optimizers\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A4.2 Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load images\n",
    "data_dir = '../deepfashionextract3/img/'\n",
    "categories = ['top', 'skirt', 'dress']\n",
    "\n",
    "data = []\n",
    "\n",
    "def create_data():\n",
    "    \n",
    "    for category in categories:\n",
    "        path = os.path.join(data_dir, category)\n",
    "        label = categories.index(category)\n",
    "\n",
    "        for filename in os.listdir(path):\n",
    "            #Load image\n",
    "            img_data = os.path.join(path, filename)\n",
    "            image = cv2.imread(img_data)\n",
    "            \n",
    "            try:\n",
    "                image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "                #Minimize to approx. one third\n",
    "                image = cv2.resize(image, (96,96))\n",
    "                image = np.array(image, dtype=np.float32)\n",
    "                \n",
    "                data.append([image, label])\n",
    "            \n",
    "            except Exception as e:\n",
    "                pass\n",
    "            \n",
    "    print(len(data))\n",
    "    \n",
    "    #wb for write and binary\n",
    "    pick = open('a_data.pickle', 'wb')\n",
    "    pickle.dump(data, pick)\n",
    "    pick.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    #rb for read and binary\n",
    "    pick = open('a_data.pickle', 'rb')\n",
    "    data = pickle.load(pick)\n",
    "    pick.close()\n",
    "    \n",
    "    #Shuffle the data\n",
    "    np.random.shuffle(data)\n",
    "    \n",
    "    feature = []\n",
    "    labels = []\n",
    "    \n",
    "    for img, label in data:\n",
    "        feature.append(img)\n",
    "        labels.append(label)\n",
    "        \n",
    "    feature = np.array(feature, dtype=np.float32 )\n",
    "    labels = np.array(labels)\n",
    "        \n",
    "    ##Normalize the pixels between 0 and 1\n",
    "    feature = feature/255.0\n",
    "    \n",
    "    return [feature, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A4.3 Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we do not have a large dataset only **10%** is saved for **test** so that more data can be used for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create model - 1 \n",
    "model = tf.keras.Model(input_layer, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create model - 2\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit model \n",
    "history = model.fit(X_train, y_train, batch_size=20, epochs=15)\n",
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following shows a summary of the **hyperparameters**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "from keras.models import load_model\n",
    "model.save('A_recognition.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A4.4 Load Different Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **new test set** is loaded to simulate a customer searching for a similar product, or a cross sale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49653</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58513</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39716</td>\n",
       "      <td>Dress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28456</td>\n",
       "      <td>Skirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31782</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    cat\n",
       "0  49653    Top\n",
       "1  58513    Top\n",
       "2  39716  Dress\n",
       "3  28456  Skirt\n",
       "4  31782    Top"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load new test set\n",
    "style_data2 = pd.read_csv('style_data2.csv', index_col=0).reset_index(drop=True)\n",
    "style_data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2,026** images of tops, skirts and dresses are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2026"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(style_data2['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is **simulated** that the customer is interested in a **random item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2769"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Based on minimum and maximum a random number is defined\n",
    "item_index = random.randint(0, 18632)\n",
    "item_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50205"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_no = style_data.iloc[item_index, 0]\n",
    "img_no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below the **selected image** is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_no' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4567762f13b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mroot_fashion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../fashion_dataset2/images/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mimage_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_no\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.jpg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mimage_name2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_fashion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_name2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img_no' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "root_fashion = '../fashion_dataset2/images/'\n",
    "\n",
    "image_name = str(img_no) + '.jpg'\n",
    "image_name2 = os.path.join(root_fashion, image_name)\n",
    "img = cv2.imread(image_name2,3) \n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (96,96))\n",
    "img = np.array(img, dtype=np.float32)\n",
    "img = img/255\n",
    "\n",
    "#prediction = model.predict(img)\n",
    "\n",
    "plt.imshow(img)\n",
    "\n",
    "#np.argmax returns the position of the largest value\n",
    "#plt.xlabel('Actual:'+categories[y_test[i]]+'\\n'+'Predicted:'+categories[np.argmax(y_pred[i])])\n",
    "plt.xticks([])\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RGB2HEX(color):\n",
    "    return \"#{:02x}{:02x}{:02x}\".format(int(color[0]), int(color[1]), int(color[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colors(image, number_of_colors):\n",
    "    \n",
    "    modified_image = cv2.resize(image, (600, 400), interpolation = cv2.INTER_AREA)\n",
    "    modified_image = modified_image.reshape(modified_image.shape[0]*modified_image.shape[1], 3)\n",
    "    \n",
    "    clf = KMeans(n_clusters = number_of_colors)\n",
    "    labels = clf.fit_predict(modified_image)\n",
    "    \n",
    "    counts = Counter(labels)\n",
    "    # sort to ensure correct color percentage\n",
    "    counts = dict(sorted(counts.items()))\n",
    "    \n",
    "    center_colors = clf.cluster_centers_\n",
    "    # We get ordered colors by iterating through the keys\n",
    "    ordered_colors = [center_colors[i] for i in counts.keys()]\n",
    "    hex_colors = [RGB2HEX(ordered_colors[i]) for i in counts.keys()]\n",
    "    rgb_colors = [ordered_colors[i] for i in counts.keys()]\n",
    "\n",
    "    return rgb_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-2006f0e7ee92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_colors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mrgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "rgb = get_colors(img, 2)\n",
    "rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframes with tops, skirts and dresses of the **DeepFashion** dataset are loaded for making **cross-selling offer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>selected_style</th>\n",
       "      <th>image_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>top</td>\n",
       "      <td>Beaded</td>\n",
       "      <td>../deepfashionextract3/img/top/Beaded_Chiffon_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>top</td>\n",
       "      <td>Beaded</td>\n",
       "      <td>../deepfashionextract3/img/top/Beaded_Chiffon_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>top</td>\n",
       "      <td>Beaded</td>\n",
       "      <td>../deepfashionextract3/img/top/Beaded_Chiffon_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>top</td>\n",
       "      <td>Beaded</td>\n",
       "      <td>../deepfashionextract3/img/top/Beaded_Chiffon_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>top</td>\n",
       "      <td>Beaded</td>\n",
       "      <td>../deepfashionextract3/img/top/Beaded_Chiffon_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category selected_style                                         image_name\n",
       "0      top         Beaded  ../deepfashionextract3/img/top/Beaded_Chiffon_...\n",
       "1      top         Beaded  ../deepfashionextract3/img/top/Beaded_Chiffon_...\n",
       "2      top         Beaded  ../deepfashionextract3/img/top/Beaded_Chiffon_...\n",
       "3      top         Beaded  ../deepfashionextract3/img/top/Beaded_Chiffon_...\n",
       "4      top         Beaded  ../deepfashionextract3/img/top/Beaded_Chiffon_..."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data with tops\n",
    "deepfashion_tops = pd.read_csv('../deepfashionextract3/deepfashion_tops.csv', index_col=0).reset_index(drop=True)\n",
    "deepfashion_tops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data with tops\n",
    "deepfashion_skirts = pd.read_csv('../deepfashionextract3/deepfashion_skirts.csv', index_col=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>selected_style</th>\n",
       "      <th>image_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dress</td>\n",
       "      <td>Embroidered</td>\n",
       "      <td>../deepfashionextract3/img/dress/Embroidered_B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dress</td>\n",
       "      <td>Embroidered</td>\n",
       "      <td>../deepfashionextract3/img/dress/Embroidered_B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dress</td>\n",
       "      <td>Embroidered</td>\n",
       "      <td>../deepfashionextract3/img/dress/Embroidered_B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dress</td>\n",
       "      <td>Embroidered</td>\n",
       "      <td>../deepfashionextract3/img/dress/Embroidered_B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dress</td>\n",
       "      <td>Embroidered</td>\n",
       "      <td>../deepfashionextract3/img/dress/Embroidered_B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category selected_style                                         image_name\n",
       "0    dress    Embroidered  ../deepfashionextract3/img/dress/Embroidered_B...\n",
       "1    dress    Embroidered  ../deepfashionextract3/img/dress/Embroidered_B...\n",
       "2    dress    Embroidered  ../deepfashionextract3/img/dress/Embroidered_B...\n",
       "3    dress    Embroidered  ../deepfashionextract3/img/dress/Embroidered_B...\n",
       "4    dress    Embroidered  ../deepfashionextract3/img/dress/Embroidered_B..."
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data with dresses\n",
    "deepfashion_dresses = pd.read_csv('../deepfashionextract3/deepfashion_dresses.csv', index_col=0).reset_index(drop=True)\n",
    "deepfashion_dresses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the prediction **three cross-selling offers** are made according to the following rules:\n",
    "\n",
    "1. If a top is predicted, a matching skirt is recommended.\n",
    "2. If a skirt is predicted, a matching top is recommended.\n",
    "3. If a dress is predicted, another dress is recommended.\n",
    "\n",
    "These suggestions are based on the assumptions that top and skirt can be **worn together**, while a person who is interested in a dress would also like to buy **other** dresses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Simulate prediction\n",
    "prediction = random.randint(0, 2)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['top', 'skirt', 'dress']\n",
    "path_top = '../deepfashionextract3/img/top/'\n",
    "path_skirt = '../deepfashionextract3/img/skirt/'\n",
    "path_dress = '../deepfashionextract3/img/dress/'\n",
    "\n",
    "def offer(prediction):\n",
    "    '''This function suggests a suitable category for a cross-selling offer.''' \n",
    "    #Prediction that it is a top\n",
    "    if prediction == 0: \n",
    "        #Recommend three skirts\n",
    "        ident = []\n",
    "        for i in range(3):\n",
    "            output = deepfashion_skirts.iloc[random.randint(0, 4000), 2]  \n",
    "            last_part = output[-16:]\n",
    "            middle = output.replace('../deepfashionextract3/img/skirt/','').replace(output[-16:],'')\n",
    "            ident.append('../deepfashionextract3/img/skirt/' + middle[:-1] + '_' + last_part)\n",
    "    #Prediction that it is a skirt\n",
    "    elif prediction == 1: \n",
    "        #Recommend three tops\n",
    "        indent = []\n",
    "        for i in range(3):\n",
    "            output = deepfashion_tops.iloc[random.randint(0, 4000), 2]\n",
    "            last_part = output[-16:]\n",
    "            middle = output.replace('../deepfashionextract3/img/top/','').replace(output[-16:],'')\n",
    "            ident.append('../deepfashionextract3/img/top/' + middle[:-1] + '_' + last_part)\n",
    "    #Prediction that it is a dress  \n",
    "    elif prediction == 2:  \n",
    "        #Recommend three dress\n",
    "        ident = []\n",
    "        for i in range(3):\n",
    "            output = deepfashion_dresses.iloc[random.randint(0, 4000), 2]   \n",
    "            last_part = output[-16:]\n",
    "            middle = output.replace('../deepfashionextract3/img/dress/','').replace(output[-16:],'')\n",
    "            ident.append('../deepfashionextract3/img/dress/' + middle[:-1] + '_' + last_part)\n",
    "    return ident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../deepfashionextract3/img/skirt/Buttoned_Daisy_Print_Skirt_img_00000037.jpg',\n",
       " '../deepfashionextract3/img/skirt/Pleated_Chiffon_Skirt_img_00000066.jpg',\n",
       " '../deepfashionextract3/img/skirt/Classic_Fold-Over_Maxi_Skirt_img_00000064.jpg']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save into variable\n",
    "cross = offer(prediction)\n",
    "cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-9d_dfo3_\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-ffe59a9f5660>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0max1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mident1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mident1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mident1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mident1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mident1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mident1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mident1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-9d_dfo3_\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Show images\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax1 = fig.add_subplot(1,3,1)\n",
    "ident1 = cv2.imread(cross[0], 3)\n",
    "ident1 = cv2.cvtColor(ident1, cv2.COLOR_BGR2RGB)\n",
    "ident1 = cv2.resize(ident1, (224,224))\n",
    "ident1 = np.array(ident1, dtype=np.float32)/255\n",
    "ax1.imshow(ident1);\n",
    "\n",
    "ax2 = fig.add_subplot(1,3,2)\n",
    "ident2 = cv2.imread(cross[1], 3)\n",
    "ident2 = cv2.cvtColor(ident2, cv2.COLOR_BGR2RGB)\n",
    "ident2 = cv2.resize(ident2, (224,224))\n",
    "ident2 = np.array(ident2, dtype=np.float32)/255\n",
    "ax2.imshow(ident2);\n",
    "\n",
    "ax3 = fig.add_subplot(1,3,3)\n",
    "ident3 = cv2.imread(cross[2], 3)\n",
    "ident3 = cv2.cvtColor(ident3, cv2.COLOR_BGR2RGB)\n",
    "ident3 = cv2.resize(ident3, (224,224))\n",
    "ident3 = np.array(ident3, dtype=np.float32)/255\n",
    "ax3.imshow(ident3);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Image data of dtype object cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-3d09151f9792>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0max1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mident1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mident1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0max2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1563\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1564\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1565\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    356\u001b[0m                 \u001b[1;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[1;32m--> 358\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    356\u001b[0m                 \u001b[1;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[1;32m--> 358\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5624\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5625\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5626\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5627\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5628\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    691\u001b[0m         if (self._A.dtype != np.uint8 and\n\u001b[0;32m    692\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[1;32m--> 693\u001b[1;33m             raise TypeError(\"Image data of dtype {} cannot be converted to \"\n\u001b[0m\u001b[0;32m    694\u001b[0m                             \"float\".format(self._A.dtype))\n\u001b[0;32m    695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Image data of dtype object cannot be converted to float"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "\n",
    "ax1 = fig.add_subplot(1,3,1)\n",
    "ident1 = cv2.imread(cross[0], 3)\n",
    "ax1.imshow(ident1);\n",
    "\n",
    "ax2 = fig.add_subplot(1,3,2)\n",
    "ident2 = cv2.imread(cross[1], 3)\n",
    "ident2 = np.array(ident2, dtype=np.float32)/255\n",
    "ident2 = cv2.resize(ident2, (224,224))\n",
    "ax2.imshow(ident2);\n",
    "\n",
    "ax3 = fig.add_subplot(1,3,3)\n",
    "ident3 = cv2.imread(cross[2], 3)\n",
    "ident3 = np.array(ident3, dtype=np.float32)/255\n",
    "ident3 = cv2.resize(ident3, (224,224))\n",
    "ax3.imshow(ident3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imread(cross[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(cross[1], 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-9d_dfo3_\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-fb1d75524c68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mshow_offer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-759d64631275>\u001b[0m in \u001b[0;36mshow_offer\u001b[1;34m(cross)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0max1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mident1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mident1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mident1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mident1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mident1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mident1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mident1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-9d_dfo3_\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_offer(cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.9056341, 0.8824864, 0.8896816], dtype=float32),\n",
       " array([0.3078322 , 0.24160016, 0.24811277], dtype=float32),\n",
       " array([0.71542  , 0.6242447, 0.6146033], dtype=float32)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Three most dominant colors\n",
    "get_colors(ident1, 3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.909032 , 0.9040282, 0.9044175], dtype=float32),\n",
       " array([0.3175158 , 0.25622487, 0.22858292], dtype=float32),\n",
       " array([0.67892617, 0.62859154, 0.59411407], dtype=float32)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Three most dominant colors\n",
    "get_colors(ident2, 3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.7896715 , 0.73356646, 0.6935267 ], dtype=float32),\n",
       " array([0.94685644, 0.9443524 , 0.9458392 ], dtype=float32),\n",
       " array([0.45818788, 0.31204343, 0.240165  ], dtype=float32)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Three most dominant colors\n",
    "get_colors(ident3, 3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_histogram(clt):\n",
    "    \"\"\"\n",
    "    create a histogram with k clusters\n",
    "    :param: clt\n",
    "    :return:hist\n",
    "    \"\"\"\n",
    "    numLabels = np.arange(0, len(np.unique(clt.labels_)) + 1)\n",
    "    (hist, _) = np.histogram(clt.labels_, bins=numLabels)\n",
    "\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= hist.sum()\n",
    "\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_colors2(hist, centroids):\n",
    "    bar = np.zeros((50, 300, 3), dtype=\"uint8\")\n",
    "    startX = 0\n",
    "\n",
    "    for (percent, color) in zip(hist, centroids):\n",
    "        # plot the relative percentage of each cluster\n",
    "        endX = startX + (percent * 300)\n",
    "        cv2.rectangle(bar, (int(startX), 0), (int(endX), 50),\n",
    "                      color.astype(\"uint8\").tolist(), -1)\n",
    "        startX = endX\n",
    "\n",
    "    # return the bar chart\n",
    "    return bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABGCAYAAABv7kdbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAABRElEQVR4nO3aMWpCURRF0f/FMekQDIi9VYRABmmTKTik6whMFfaHuFb7mlNtbvHWmVkAaOy2HgDwTkQXICS6ACHRBQiJLkBIdAFC+98eT4ej/2QvXD9vy8flsvUM/omZWR4/961n8EfOX9/rqzeXLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6AKF1ZrbeAPA2XLoAIdEFCIkuQEh0AUKiCxASXYDQExHKEIdmvo8mAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Color of option1\n",
    "img = cv2.imread(ident1)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "img = img.reshape((img.shape[0] * img.shape[1],3)) #represent as row*column,channel number\n",
    "clt = KMeans(n_clusters=3) #cluster number\n",
    "clt.fit(img)\n",
    "\n",
    "hist = find_histogram(clt)\n",
    "bar = plot_colors2(hist, clt.cluster_centers_)\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(bar)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Color of option2\n",
    "img = cv2.imread(ident2)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "img = img.reshape((img.shape[0] * img.shape[1],3)) #represent as row*column,channel number\n",
    "clt = KMeans(n_clusters=3) #cluster number\n",
    "clt.fit(img)\n",
    "\n",
    "hist = find_histogram(clt)\n",
    "bar = plot_colors2(hist, clt.cluster_centers_)\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(bar)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Color of option3\n",
    "img = cv2.imread(ident3)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "img = img.reshape((img.shape[0] * img.shape[1],3)) #represent as row*column,channel number\n",
    "clt = KMeans(n_clusters=3) #cluster number\n",
    "clt.fit(img)\n",
    "\n",
    "hist = find_histogram(clt)\n",
    "bar = plot_colors2(hist, clt.cluster_centers_)\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(bar)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
